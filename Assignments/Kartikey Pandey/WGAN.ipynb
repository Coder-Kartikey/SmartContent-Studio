{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee643b4-39e8-4b87-922c-dfd5e19d0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras import backend\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.constraints import Constraint\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c02306-388a-48fc-a38d-e5db63a0892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define wasserstein loss function\n",
    "#Goal is to minimize the Wasserstein distance between distribution of generated samples and distribution of real samples.\n",
    "#We take the average distance, so we use backend.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e683ee65-9722-4461-b0fe-db1572d5650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return backend.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693981a-035e-4100-9e93-7344d013b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate images\n",
    "#generate the images from the dataset as follows: We will be using the class of digit 5, we can use any value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087b176e-9d8d-494f-b653-23be3b7bc631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from the dataset\n",
    "def load_real_samples():\n",
    "    (trainX, trainy), (_, _) = load_data()\n",
    "    selected_ix = trainy == 5\n",
    "    X = trainX[selected_ix]\n",
    "    X = expand_dims(X, axis=-1)\n",
    "    X = X.astype('float32')\n",
    "    X = (X - 127.5) / 127.5\n",
    "    return X\n",
    "\n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = -ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df305f2-14b6-4e62-8174-a6dcb3789764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Samples\n",
    "#Randomly we need to generate real samples from the dataset above we chosen as X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99dfa06c-0e86-4b3c-80dd-f0a4ac768460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = -ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0591b506-15b0-4b30-b05e-68f331efc5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Critic and Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c2239-5656-41c1-9f93-acb87679788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the discriminator model more than generator since it needs to be more accurate otherwise the generator will easily \n",
    "#make it fool.\n",
    "#clip constraint to be applied on our weights since we discussed we need the gradient descent and hence we make it cubic clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b703677-12b3-4a0f-aaad-b4995d8c828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip model\n",
    "class ClipConstraint(Constraint):\n",
    "    def __init__(self, clip_value):\n",
    "        self.clip_value = clip_value\n",
    "    def __call__(self, weights):\n",
    "        return backend.clip(weights, -self.clip_value, self.clip_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c902c-7ee1-411f-864d-f9451437d3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a10e074a-1962-4049-b772-05dbeea28c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# critic model\n",
    "def define_critic(in_shape=(28,28,1)):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = ClipConstraint(0.01)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    opt = RMSprop(lr=1)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae8b85d-de6f-4f16-a9f0-5deb03535b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Generator Model\n",
    "#In the generator model, we simply take a 28x28 image and downscale it to 7x7 for better performance and model it accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3084b6b7-fe4c-4645-a254-e05fbf47d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "\n",
    "    init = RandomNormal(stddev=0.03)\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    n_nodes = 128 * 7 * 7\n",
    "    model.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29bc7429-2fa2-475d-a512-b424477c3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the generator\n",
    "#use the Root Mean Square as our optimizer for the generator since the Adam optimizer generates problem for the model.\n",
    "def define_gan(generator, critic):\n",
    "    # make weights in the critic not trainable\n",
    "    for layer in critic.layers:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(critic)\n",
    "    opt = RMSprop(lr=1)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "124611be-e12e-4679-bf6a-f9b8808038e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Fake Samples using latent space\n",
    "#Take the latent space and the number of samples and then ask the generator to predict the samples.\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "# fake examples\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = generator.predict(x_input)\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862bffd9-0dcf-44ea-a1f4-675932d39f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training\n",
    "#update the critic/discrimnator more than the generator to make it flawless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25aa2640-700a-43b3-a4cc-3a36aa110bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and critic\n",
    "def train(g_model, c_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=64, n_critic=5):\n",
    "    # number of batches per training epoch\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    # number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # size of half a batch of samples\n",
    "    half_batch = int(n_batch / 2)\n",
    "    \n",
    "    c1_hist, c2_hist, g_hist = list(), list(), list()\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        # update the critic\n",
    "        c1_tmp, c2_tmp = list(), list()\n",
    "        for _ in range(n_critic):\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            c_loss1 = c_model.train_on_batch(X_real, y_real)\n",
    "            c1_tmp.append(c_loss1)\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            c_loss2 = c_model.train_on_batch(X_fake, y_fake)\n",
    "            c2_tmp.append(c_loss2)\n",
    "        c1_hist.append(mean(c1_tmp))\n",
    "        c2_hist.append(mean(c2_tmp))\n",
    "        X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "        y_gan = -ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "        g_hist.append(g_loss)\n",
    "        print('&gt;%d, c1=%.3f, c2=%.3f g=%.3f' % (i+1, c1_hist[-1], c2_hist[-1], g_loss))\n",
    "        # evaluate the model performance every 'epoch'\n",
    "        if (i+1) % bat_per_epo == 0:\n",
    "            summarize_performance(i, g_model, latent_dim)\n",
    "    # line plots of loss\n",
    "    plot_history(c1_hist, c2_hist, g_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81676f0a-60c2-4288-96ed-adebd06bb59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization\n",
    "#Use the following plot functions and can check the history plot in your directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdf44d90-c9ce-4f89-85c9-ff7e0dca913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
    "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    X = (X + 1) / 2.0\n",
    "    for i in range(10 * 10):\n",
    "        pyplot.subplot(10, 10, 1 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "    filename1 = 'plot_%04d.png' % (step+1)\n",
    "    pyplot.savefig(filename1)\n",
    "    pyplot.close()\n",
    "\n",
    "def plot_history(d1_hist, d2_hist, g_hist):\n",
    "    # plot history\n",
    "    pyplot.plot(d1_hist, label='crit_real')\n",
    "    pyplot.plot(d2_hist, label='crit_fake')\n",
    "    pyplot.plot(g_hist, label='gen')\n",
    "    pyplot.legend()\n",
    "    pyplot.savefig('line_plot_loss.png')\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c8018c1-72fa-4f82-8470-7ca56daca913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Mohan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Argument(s) not recognized: {'lr': 5e-05}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#To test it run it as follows:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m latent_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m----> 3\u001b[0m critic \u001b[38;5;241m=\u001b[39m define_critic()\n\u001b[0;32m      4\u001b[0m generator \u001b[38;5;241m=\u001b[39m define_generator(latent_dim)\n\u001b[0;32m      5\u001b[0m gan_model \u001b[38;5;241m=\u001b[39m define_gan(generator, critic)\n",
      "Cell \u001b[1;32mIn[7], line 14\u001b[0m, in \u001b[0;36mdefine_critic\u001b[1;34m(in_shape)\u001b[0m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Flatten())\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 14\u001b[0m opt \u001b[38;5;241m=\u001b[39m RMSprop(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00005\u001b[39m)\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mwasserstein_loss, optimizer\u001b[38;5;241m=\u001b[39mopt)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\rmsprop.py:72\u001b[0m, in \u001b[0;36mRMSprop.__init__\u001b[1;34m(self, learning_rate, rho, momentum, epsilon, centered, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     55\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     71\u001b[0m ):\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     73\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m     74\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m     75\u001b[0m         clipnorm\u001b[38;5;241m=\u001b[39mclipnorm,\n\u001b[0;32m     76\u001b[0m         clipvalue\u001b[38;5;241m=\u001b[39mclipvalue,\n\u001b[0;32m     77\u001b[0m         global_clipnorm\u001b[38;5;241m=\u001b[39mglobal_clipnorm,\n\u001b[0;32m     78\u001b[0m         use_ema\u001b[38;5;241m=\u001b[39muse_ema,\n\u001b[0;32m     79\u001b[0m         ema_momentum\u001b[38;5;241m=\u001b[39mema_momentum,\n\u001b[0;32m     80\u001b[0m         ema_overwrite_frequency\u001b[38;5;241m=\u001b[39mema_overwrite_frequency,\n\u001b[0;32m     81\u001b[0m         loss_scale_factor\u001b[38;5;241m=\u001b[39mloss_scale_factor,\n\u001b[0;32m     82\u001b[0m         gradient_accumulation_steps\u001b[38;5;241m=\u001b[39mgradient_accumulation_steps,\n\u001b[0;32m     83\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     85\u001b[0m     )\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrho \u001b[38;5;241m=\u001b[39m rho\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;241m=\u001b[39m momentum\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\optimizer.py:21\u001b[0m, in \u001b[0;36mTFOptimizer.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:90\u001b[0m, in \u001b[0;36mBaseOptimizer.__init__\u001b[1;34m(self, learning_rate, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `decay` is no longer supported and will be ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m     )\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument(s) not recognized: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     name \u001b[38;5;241m=\u001b[39m auto_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Argument(s) not recognized: {'lr': 5e-05}"
     ]
    }
   ],
   "source": [
    "#To test it run it as follows:\n",
    "latent_dim = 50\n",
    "critic = define_critic()\n",
    "generator = define_generator(latent_dim)\n",
    "gan_model = define_gan(generator, critic)\n",
    "dataset = load_real_samples()\n",
    "print(dataset.shape)\n",
    "train(generator, critic, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd36bc35-84bd-44f7-9cb4-8e92f6eb8c64",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1541442097.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[25], line 16\u001b[1;36m\u001b[0m\n\u001b[1;33m    imageio.mimsave('/content/output.gif', images,format=&quot;GIF&quot;, fps=2)\u001b[0m\n\u001b[1;37m                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#merge the plots as follows:\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "imgdir = '/content/'\n",
    "\n",
    "gif_files = [file for file in os.listdir(imgdir) if file.startswith('plot_')]\n",
    "\n",
    "gif_files.sort()\n",
    "\n",
    "images = []\n",
    "for image_file in gif_files:\n",
    "    image_path = os.path.join(imgdir, image_file)\n",
    "    images.append(imageio.imread(image_path))\n",
    "\n",
    "imageio.mimsave('/content/output.gif', images,format=&quot;GIF&quot;, fps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e88c165-eac9-486f-b2fa-8fa3ed7a61af",
   "metadata": {},
   "source": [
    "# Observations\n",
    "1. As we see, before the epoch 300, we have very unclear generation, and it doesn't correlates to digit 5.\n",
    "2. #But after that, we see some good generation of fake digits which appears real.\n",
    "3. #Hence, we see clearer images as we progress.\n",
    "4. #At the starting stage, the generator gets adjusted to compete with discriminator and provides initialized data modified slightly.\n",
    "5. After running several epochs, generator gets adjusted and produces good results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
